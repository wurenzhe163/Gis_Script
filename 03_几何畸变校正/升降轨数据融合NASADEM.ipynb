{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载、角度运算、初始化叠掩阴影、直方图匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T02:43:57.971305Z",
     "start_time": "2023-09-02T02:43:36.208555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Wrz\\anaconda\\envs\\GEE\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geemap version = 0.20.0\n",
      "geemap path = ['D:\\\\Wrz\\\\anaconda\\\\envs\\\\GEE\\\\lib\\\\site-packages\\\\geemap']\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import geemap.chart as chart\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import math\n",
    "import sys,os\n",
    "sys.path.append(os.path.dirname(os.path.abspath('__file__')))\n",
    "from tqdm import trange,tqdm\n",
    "from Basic_tools import *\n",
    "from New_Correct import *\n",
    "from Correct_filter import *\n",
    "from S2_filter import *\n",
    "from functools import partial\n",
    "import geopandas as gpd\n",
    "geemap.set_proxy(port=10809)\n",
    "# ee.Authenticate()\n",
    "ee.Initialize()\n",
    "print('geemap version = {}\\ngeemap path = {}'.format(geemap.__version__,geemap.__path__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T02:43:58.918258Z",
     "start_time": "2023-09-02T02:43:57.974304Z"
    }
   },
   "outputs": [],
   "source": [
    "Glacial_lake_2015A = ee.FeatureCollection(\n",
    "    'projects/ee-mrwurenzhe/assets/Glacial_lake/Wu_Asia_Southest_GL_wgs84').filter(ee.Filter.gte('GL_Area', 0.1))\n",
    "    #projects/ee-mrwurenzhe/assets/Glacial_lake/Checkout_polygen\n",
    "\n",
    "# 计算geometry、质心点、最小包络矩形\n",
    "Geo_ext = lambda feature: feature.set({\n",
    "    'Geo': feature.geometry(),\n",
    "    'Centroid': feature.geometry().centroid(),\n",
    "    'Rectangle': feature.geometry().bounds()\n",
    "})\n",
    "\n",
    "Centrid_set = lambda feature: feature.setGeometry(feature.geometry().centroid())\n",
    "Rectangle_set = lambda feature: feature.setGeometry(feature.geometry().bounds())\n",
    "Glacial_lake_2015C = Glacial_lake_2015A.map(Geo_ext).map(Centrid_set)  # 添加属性,修改geometry,计算质心\n",
    "Glacial_lake_2015R = Glacial_lake_2015A.map(Rectangle_set)       # 计算最小包络矩形\n",
    "\n",
    "#抽取属性作为list\n",
    "Glacial_lake_2015A_GeoList = ee.List(Glacial_lake_2015C.reduceColumns(ee.Reducer.toList(), ['Geo']).get('list'))\n",
    "Glacial_lake_2015C_CentriodList = ee.List(Glacial_lake_2015C.reduceColumns(ee.Reducer.toList(),['Centroid']).get('list'))\n",
    "Glacial_lake_2015R_RectangleList = ee.List(Glacial_lake_2015C.reduceColumns(ee.Reducer.toList(),['Rectangle']).get('list'))\n",
    "Num_list = Glacial_lake_2015C_CentriodList.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T02:44:03.284354Z",
     "start_time": "2023-09-02T02:43:58.921261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Filter ...\n"
     ]
    }
   ],
   "source": [
    "# 选择一个时间点的影像，注意SAR和光学影像的时间点已经不一样了\n",
    "# 需要放宽一些时间限制，否则可能会因为天气影响、卫星维护等问题出现数据缺失\n",
    "START_DATE  = ee.Date('2019-07-01')\n",
    "END_DATE   = ee.Date('2019-08-30')\n",
    "TIME_LEN   = END_DATE.difference(START_DATE, 'days').abs()\n",
    "MIDDLE_DATE  = START_DATE.advance(TIME_LEN.divide(ee.Number(2)).int(),'days')\n",
    "\n",
    "DEMSRTM = ee.Image('USGS/SRTMGL1_003')\n",
    "DEM_prj = DEMSRTM.projection()\n",
    "DEMNASA = ee.Image(\"NASA/NASADEM_HGT/001\").select('elevation')\n",
    "DEMALOS = ee.ImageCollection(\"JAXA/ALOS/AW3D30/V3_2\").mosaic().select('DSM').rename('elevation').reproject(DEM_prj)\n",
    "DEMCOPERNICUS = ee.ImageCollection(\"COPERNICUS/DEM/GLO30\").mosaic().select('DEM').rename('elevation').int16().reproject(DEM_prj)\n",
    "\n",
    "\n",
    "models = ['volume', 'surface', None]     # 地形矫正模型\n",
    "Model = models[0]\n",
    "Origin_scale = 10\n",
    "projScale = 30\n",
    "\n",
    "\n",
    "# 选择一个点做实验\n",
    "i=1143 #394(面积大) #53 #11(影像都用nodata) #149(坐标系问题) #1143(畸变) #539(中等交并比)  #1296(高等交并比)\n",
    "\n",
    "AOI_point = ee.Feature.geometry(Glacial_lake_2015C_CentriodList.get(i))\n",
    "AOI_area = ee.Feature.geometry(Glacial_lake_2015A_GeoList.get(i))\n",
    "AOI = ee.Feature.geometry(Glacial_lake_2015R_RectangleList.get(i))\n",
    "\n",
    "# 计算面积\n",
    "AOI_area_area = AOI_area.area().divide(ee.Number(1000*1000)).getInfo()\n",
    "# 缩小\n",
    "if AOI_area_area < 1:\n",
    "    AOI_area_buffer = AOI_area.buffer(distance=AOI_area_area*-300)\n",
    "else:\n",
    "    AOI_area_buffer = AOI_area.buffer(distance=-400)\n",
    "\n",
    "# 扩大包络矩形AOI,保证背景像素占比最大，原有基础上相应+100\n",
    "if AOI_area_area < 1:\n",
    "    AOI_buffer = AOI.buffer(distance=400).bounds()\n",
    "else:\n",
    "    AOI_buffer = AOI.buffer(distance=500).bounds()\n",
    "\n",
    "# 载入图像，采用滤波函数，筛选日期，AOI_buffer仅用于统计是否有空值点\n",
    "s1_ascending, s1_descending = load_image_collection(AOI_buffer,START_DATE,END_DATE,MIDDLE_DATE,\n",
    "                                                            Filter='RefinedLee',FilterSize=30)\n",
    "\n",
    "CLOUD_FILTER = 60           # 过滤s2 大于指定云量的数据\n",
    "CLD_PRB_THRESH = 15         # s2cloudless 概率值阈值[0-100],原实验是50\n",
    "NIR_DRK_THRESH = 0.15       # 非水暗像素判断阈值\n",
    "CLD_PRJ_DIST = 1            # 根据 CLD_PRJ_DIST 输入指定的距离从云中投射阴影\n",
    "BUFFER = 50                 # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input\n",
    "# 采用S2cloudless生产一张合成的无云图像\n",
    "s2_sr_median = merge_s2_collection(AOI_buffer,START_DATE,END_DATE,\n",
    "                      CLOUD_FILTER,BUFFER,CLD_PRJ_DIST,CLD_PRB_THRESH,NIR_DRK_THRESH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算几何畸变区域，然后采用ImageCollection进行融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T02:44:23.811879Z",
     "start_time": "2023-09-02T02:44:03.287354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with slop correction and volumetric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 138.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 57.24it/s]\n"
     ]
    }
   ],
   "source": [
    "def CalDitorAndCombin(s1_ascending,s1_descending,Bands_ = ['VV_gamma0_flatDB','VH_gamma0_flatDB'],):\n",
    "  # 当'synthesis': 1，则跳过几何畸变校正步骤，直接进入识别\n",
    "  synthesis_a  = ee.Image(s1_ascending).get('synthesis').getInfo()\n",
    "  synthesis_d  = ee.Image(s1_descending).get('synthesis').getInfo()\n",
    "  if synthesis_a or synthesis_d:\n",
    "      print('Image with synthesis')\n",
    "      Combin_ad = ee.ImageCollection([s1_ascending,s1_descending])\n",
    "      s1_unit_mean_ = Combin_ad.mean()\n",
    "      s1_unit_max_  = Combin_ad.max()\n",
    "      s1_unit_min_  = Combin_ad.min()\n",
    "  else:\n",
    "      print('Image with slop correction and volumetric')\n",
    "      volumetric_dict = my_slope_correction(s1_ascending,s1_descending,AOI_buffer,DEMNASA,Model,Origin_scale)\n",
    "\n",
    "  # ----------------------Z-scor均衡化，直方图匹配，在局部进行直方图匹配\n",
    "  Bands_ = Bands_\n",
    "  Ascending_Img = volumetric_dict['ASCENDING'].select(Bands_)\n",
    "  Descending_Img = volumetric_dict['DESCENDING'].select(Bands_)\n",
    "\n",
    "  ASCENDING_meanStd = meanStd_norm(Ascending_Img,Bands_,scale=Origin_scale)\n",
    "  DESSCENDING_meanStd = meanStd_norm(Descending_Img,Bands_,scale=Origin_scale)\n",
    "\n",
    "  # 经过z-score，无需再进行均值迁移\n",
    "  Match_Ascending = histogramMatching(ASCENDING_meanStd, DESSCENDING_meanStd\n",
    "                      ,AOI_buffer,Bands_,Bands_\n",
    "                      ,Histscale=projScale,maxBuckets=1024).clip(AOI_buffer)\n",
    "\n",
    "  volumetric_dict['ASCENDING'] = replaceBands(volumetric_dict['ASCENDING'],Match_Ascending)\n",
    "  volumetric_dict['DESCENDING'] = replaceBands(volumetric_dict['DESCENDING'],DESSCENDING_meanStd)\n",
    "\n",
    "\n",
    "  # -----------------------基于线性关系。检测几何畸变\n",
    "  Templist_A = AuxiliaryLine2Point(volumetric_dict['ASCENDING'],volumetric_dict['ASCENDING_parms']['s1_azimuth_across'],\n",
    "                                volumetric_dict['ASCENDING_parms']['coordinates_dict'],\n",
    "                                volumetric_dict['ASCENDING_parms']['Auxiliarylines'],\n",
    "                                projScale)\n",
    "  LeftLayoverA,RightLayoverA,ShadowA = Line_Correct(volumetric_dict['ASCENDING'],AOI_buffer,Templist_A,'ASCENDING',\n",
    "                                                volumetric_dict['ASCENDING_parms']['proj'],projScale,Origin_scale)\n",
    "\n",
    "  Templist_D = AuxiliaryLine2Point(volumetric_dict['DESCENDING'],volumetric_dict['DESCENDING_parms']['s1_azimuth_across'],\n",
    "                                volumetric_dict['DESCENDING_parms']['coordinates_dict'],\n",
    "                                volumetric_dict['DESCENDING_parms']['Auxiliarylines'],\n",
    "                                projScale)\n",
    "  LeftLayoverD,RightLayoverD,ShadowD =  Line_Correct(volumetric_dict['DESCENDING'],AOI_buffer,Templist_D,'DESCENDING',\n",
    "                                                volumetric_dict['DESCENDING_parms']['proj'],projScale,Origin_scale)\n",
    "\n",
    "\n",
    "  def Cal_mask(LeftLayover,RightLayover,Shadow,AOI_buffer):\n",
    "      # 判断是否为空\n",
    "      left_empty = LeftLayover.bandNames().length().eq(0)\n",
    "      right_empty = RightLayover.bandNames().length().eq(0)\n",
    "      shadow_empty = Shadow.bandNames().length().eq(0)\n",
    "\n",
    "      # 只合并非空图像\n",
    "      result = ee.Image(ee.Algorithms.If(left_empty, ee.Image(), LeftLayover))\n",
    "      result = ee.Image(ee.Algorithms.If(right_empty,result,result.Or(RightLayover)))\n",
    "      result = ee.Image(ee.Algorithms.If(shadow_empty,result,result.Or(Shadow)))\n",
    "      return result.clip(AOI_buffer)\n",
    "\n",
    "  LeftLayoverA,RightLayoverA,ShadowA = LeftLayoverA.mask(),RightLayoverA.mask(),ShadowA.mask()\n",
    "  LeftLayoverD,RightLayoverD,ShadowD = LeftLayoverD.mask(),RightLayoverD.mask(),ShadowD.mask()\n",
    "\n",
    "  A_mask_ = Cal_mask(LeftLayoverA,RightLayoverA,ShadowA,AOI_buffer)\n",
    "  D_mask_ = Cal_mask(LeftLayoverD,RightLayoverD,ShadowD,AOI_buffer)\n",
    "  All_distor = A_mask_.And(D_mask_)\n",
    "\n",
    "  A_empty = A_mask_.bandNames().contains('constant')\n",
    "  A_empty = ee.Number(ee.Algorithms.If(A_empty, 1, 0))\n",
    "  D_empty = D_mask_.bandNames().contains('constant')\n",
    "  D_empty = ee.Number(ee.Algorithms.If(D_empty, 1, 0))\n",
    "\n",
    "  s1_ascending  = volumetric_dict['ASCENDING'].select([\"VV_gamma0_flatDB\",\"VH_gamma0_flatDB\"])\n",
    "  s1_descending = volumetric_dict['DESCENDING'].select([\"VV_gamma0_flatDB\",\"VH_gamma0_flatDB\"])\n",
    "\n",
    "  s1_ascending_ = ee.Image(ee.Algorithms.If(A_empty, ee.Image(), s1_ascending.where(A_mask_,s1_descending)))\n",
    "  s1_descending_ = ee.Image(ee.Algorithms.If(D_empty, ee.Image(), s1_descending.where(D_mask_,s1_ascending)))\n",
    "  Combin_AD = ee.ImageCollection([s1_ascending_,s1_descending_])\n",
    "\n",
    "  s1_unit_mean_ = ee.Image(ee.Algorithms.If(A_empty.Or(D_empty),\n",
    "                s1_ascending.add(s1_descending).divide(2),\n",
    "                Combin_AD.mean()))\n",
    "\n",
    "  s1_unit_max_ = ee.Image(ee.Algorithms.If(A_empty.Or(D_empty),\n",
    "                s1_ascending.max(s1_descending),\n",
    "                Combin_AD.max()))\n",
    "\n",
    "  s1_unit_min_ = ee.Image(ee.Algorithms.If(A_empty.Or(D_empty),\n",
    "                s1_ascending.min(s1_descending),\n",
    "                Combin_AD.min()))\n",
    "  return volumetric_dict,s1_unit_mean_,s1_unit_max_,s1_unit_min_\n",
    "\n",
    "volumetric_dict,s1_unit_mean_,s1_unit_max_,s1_unit_min_ = \\\n",
    "            CalDitorAndCombin(s1_ascending,s1_descending,Bands_ = ['VV_gamma0_flatDB','VH_gamma0_flatDB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T02:45:09.831614Z",
     "start_time": "2023-09-02T02:44:23.813880Z"
    },
    "lang": "en"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1142c57bd6a46bc89b321f2cbf41a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[30.17633983666919, 94.28168536063386], controls=(WidgetControl(options=['position', 'transparent_b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map() # basemap='HYBRID'\n",
    "Map.centerObject(AOI_buffer, zoom=15)\n",
    "# Map.addLayer(volumetric_dict['ASCENDING'].select('red','green','blue'), {'min':0,'max':255}, 'no_data_maskrgb')\n",
    "# Map.addLayer(LeftLayover.randomVisualizer(),{},'LeftLayover')\n",
    "# Map.addLayer(RightLayover.randomVisualizer(),{},'RightLayover')\n",
    "# Map.addLayer(Shadow.randomVisualizer(),{},'Shadow')\n",
    "Map.addLayer(s2_sr_median,{'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 2000, 'gamma': 2.0},'s2_sr_median')\n",
    "Map.addLayer(A_mask_.randomVisualizer(),{},'A_mask')\n",
    "Map.addLayer(D_mask_.randomVisualizer(),{},'D_mask')\n",
    "Map.addLayer(volumetric_dict['ASCENDING'].select('red','green','blue'), {'min':0,'max':255}, 'no_data_maskrgb_A')\n",
    "Map.addLayer(volumetric_dict['DESCENDING'].select('red','green','blue'), {'min':0,'max':255}, 'no_data_maskrgb_D')\n",
    "Map.addLayer(All_distor.randomVisualizer().clip(AOI_buffer), {}, 'All_distor')\n",
    "\n",
    "Map.addLayer(volumetric_dict['ASCENDING'].select(\"VV_sigma0\"),{'min':-18,'max':5},'ascending')\n",
    "Map.addLayer(volumetric_dict['DESCENDING'].select(\"VV_sigma0\"),{'min':-18,'max':5},'descending')\n",
    "\n",
    "Map.addLayer(volumetric_dict['ASCENDING'].select(\"VV_gamma0_flatDB\"),{'min':-2,'max':2},'ascending_flat')\n",
    "Map.addLayer(volumetric_dict['DESCENDING'].select(\"VV_gamma0_flatDB\"),{'min':-2,'max':2},'descending_flat')\n",
    "\n",
    "Map.addLayer(s1_unit_mean_.select(\"VV_gamma0_flatDB\"),{'min':-2,'max':2},'s1_unit_mean_')\n",
    "Map.addLayer(s1_unit_max_.select(\"VV_gamma0_flatDB\"),{'min':-2,'max':2},'s1_unit_max_')\n",
    "Map.addLayer(s1_unit_min_.select(\"VV_gamma0_flatDB\"),{'min':-2,'max':2},'s1_unit_min_')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取冰湖，检测效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T02:45:09.847615Z",
     "start_time": "2023-09-02T02:45:09.834614Z"
    }
   },
   "outputs": [],
   "source": [
    "# MeanStd归一化，保留中间90%,以-2-2近似替代\n",
    "def Percent90(Image:ee.Image):\n",
    "    Image = Image.where(Image.gte(2),2)\n",
    "    Image = Image.where(Image.lte(-2),-2)\n",
    "    return Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T02:45:25.341754Z",
     "start_time": "2023-09-02T02:45:09.850616Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from Extract_algorithm import Cluster_extract as Cluster\n",
    "\n",
    "def Cluster_math(method: str, img, bands: list, index: str, visual: bool, save: bool, region=None):\n",
    "    '''method ('Kmean','SNIC','SNIC_Kmean','LVQ','Xmeans','Cobweb','CascadeKMeans')'''\n",
    "    img = img.select(bands)\n",
    "    img = Percent90(img).clip(region)\n",
    "    img = minmax_norm(img,bands,scale=Origin_scale)\n",
    "\n",
    "    if method == 'Kmean':\n",
    "        result = Cluster.afn_Kmeans(img, region)\n",
    "    elif method == 'Cobweb':\n",
    "        result = Cluster.afn_Cobweb(img, region)\n",
    "    elif method == 'Xmeans':\n",
    "        result = Cluster.afn_Xmeans(img, region)\n",
    "    elif method == 'LVQ':\n",
    "        result = Cluster.afn_LVQ(img, region)\n",
    "    elif method == 'CascadeKMeans':\n",
    "        result = Cluster.afn_CascadeKMeans(img, region)\n",
    "    elif method == 'SNIC':\n",
    "        result = Cluster.afn_SNIC(img)\n",
    "        result = result.select(result.bandNames().removeAll(['clusters', 'seeds']))\n",
    "        result = result.reproject(result.select(0).projection().getInfo()['crs'], None, 10)\n",
    "    elif method == 'SNIC_Kmean':\n",
    "        result = Cluster.afn_SNIC(img)\n",
    "        # 默认舍弃cluster和seed\n",
    "        result = result.select(result.bandNames().removeAll(['clusters', 'seeds']))\n",
    "        result = result.reproject(result.select(0).projection().getInfo()['crs'], None, 10)\n",
    "        result0 = Cluster.afn_Kmeans(result, region)  # 原始图像不参与\n",
    "        result1 = Cluster.afn_Kmeans(result.addBands(img), region)  # 原始图像参与    .unmask(10)\n",
    "\n",
    "    if visual:\n",
    "        Map = geemap.Map(basemap='HYBRID')  #\n",
    "        Map.centerObject(AOI_point, zoom=15)\n",
    "        Map.addLayer(img, {'min': 0.2, 'max': 0.8}, 'Origin')\n",
    "        if method in ['Kmean', 'Cobweb', 'Xmeans', 'LVQ', 'CascadeKMeans']:\n",
    "            Map.addLayer(result.randomVisualizer(), {}, method)\n",
    "        elif method == 'SNIC':\n",
    "            Map.addLayer(result.randomVisualizer(), {}, method)\n",
    "        elif method == 'SNIC_Kmean':\n",
    "            Map.addLayer(result0.randomVisualizer(), {}, 'SNIC_Kmean_NoOrigin')\n",
    "            Map.addLayer(result1.randomVisualizer(), {}, 'SNIC_Kmean_YesOrigin')\n",
    "        else:\n",
    "            print('Please check your method str')\n",
    "    else:\n",
    "        Map = None\n",
    "    if save:\n",
    "        if method == 'SNIC_Kmean':\n",
    "            Geemap_export(filename=index + 'NoOrigin' + method + '.tif', collection=False, image=result0,\n",
    "                          region=region, scale=10)\n",
    "            Geemap_export(filename=index + 'YesOrigin' + method + '.tif', collection=False, image=result1,\n",
    "                          region=region, scale=10)\n",
    "        else:\n",
    "            Geemap_export(filename=index + method + '.tif', collection=False, image=result, region=region, scale=10)\n",
    "        pass\n",
    "    if method == 'SNIC_Kmean':\n",
    "        return Map, result0.addBands(result1)\n",
    "    else:\n",
    "        return Map, result\n",
    "\n",
    "Map,result=Cluster_math(method='Kmean',img=s1_unit_mean_,bands=['VV_gamma0_flatDB', 'VH_gamma0_flatDB'],\n",
    "                        index='',visual=True,save=False,region=AOI_buffer)  # 如果迭代多个影像可以采用调整index\n",
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.432Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from Extract_algorithm import Adaptive_threshold as Adap\n",
    "\n",
    "def Bandmath(method:str,img,band,index:str,visual:bool,save:bool,region=None):\n",
    "    '''\n",
    "    method = ['otsu','histPeak']\n",
    "    img: 仅单波段图像\n",
    "    '''\n",
    "    img = img.select(band)\n",
    "#     assert len(img.bandNames().getInfo()) == 1 , '图像波段数必须唯一'\n",
    "    img = Percent90(img).clip(region)\n",
    "    img = minmax_norm(img,band,scale=Origin_scale)\n",
    "\n",
    "    if method == 'otsu':\n",
    "        histogram = get_histogram(img,region=region)\n",
    "        Threshould_value = Adap.afn_otsu(histogram)\n",
    "        result = img.select(0).gt(Threshould_value)  #\n",
    "        print('Threshould value is {}'.format(Threshould_value.getInfo()))\n",
    "\n",
    "    elif method == 'histPeak':\n",
    "        Threshould_value = Adap.afn_histPeak(img,region=region)\n",
    "        result = img.gt(Threshould_value)\n",
    "        print('Threshould value is {}'.format(Threshould_value))\n",
    "\n",
    "    if visual:\n",
    "        Map = geemap.Map(basemap='HYBRID') #\n",
    "        Map.centerObject(AOI_point, zoom=15)\n",
    "        if method in ['otsu','histPeak']:\n",
    "            Map.addLayer(result.randomVisualizer(), {}, method)\n",
    "        else:\n",
    "            print('Wrong visual! Please check your method str')\n",
    "\n",
    "    if save:\n",
    "        if method in ['otsu','histPeak']:\n",
    "            Geemap_export(filename=index+method+'.tif',collection=False,\n",
    "                          image=result,region=region,scale=10)\n",
    "    else:\n",
    "        print('Wrong save! Please check your method str')\n",
    "\n",
    "    return Map,result\n",
    "\n",
    "Map,result = Bandmath(method='histPeak',img=s1_unit_mean_,band=['VV_gamma0_flatDB'],index='',visual=True,save=False,region=AOI,)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.456Z"
    }
   },
   "outputs": [],
   "source": [
    "method='histPeak';img=s1_unit_mean_;band=['VV_gamma0_flatDB'];index='';visual=True;save=False;region=AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.473Z"
    }
   },
   "outputs": [],
   "source": [
    "img = img.select(band)\n",
    "assert len(img.bandNames().getInfo()) == 1 , '图像波段数必须唯一'\n",
    "img = Percent90(img).clip(region)\n",
    "img = minmax_norm(img,band,scale=Origin_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.492Z"
    }
   },
   "outputs": [],
   "source": [
    "if method == 'otsu':\n",
    "    histogram = get_histogram(img,region=region)\n",
    "    Threshould_value = Adap.afn_otsu(histogram)\n",
    "    result = img.select(0).gt(Threshould_value)  #\n",
    "    print('Threshould value is {}'.format(Threshould_value.getInfo()))\n",
    "\n",
    "elif method == 'histPeak':\n",
    "    Threshould_value = Adap.afn_histPeak(img,region=region)\n",
    "    result = img.gt(Threshould_value)\n",
    "    print('Threshould value is {}'.format(Threshould_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.543Z"
    }
   },
   "outputs": [],
   "source": [
    "from Extract_algorithm import Reprocess,save_parms\n",
    "os.chdir('/content/drive/My Drive/Output/2018预测数据')\n",
    "Methods = ('SNIC_Kmean',)\n",
    "resultbands = (0,1)\n",
    "Bands = ([0,1],)\n",
    "mode='gpd'\n",
    "logname = 'preSNIC_Kmean.csv'\n",
    "shpname = 'preSNIC_Kmean.shp'\n",
    "\n",
    "for i in trange(Num_list):\n",
    "    AOI_point = ee.Feature.geometry(Glacial_lake_2015C_CentriodList.get(i))\n",
    "    AOI_area = ee.Feature.geometry(Glacial_lake_2015A_GeoList.get(i))\n",
    "    AOI = ee.Feature.geometry(Glacial_lake_2015R_RectangleList.get(i))\n",
    "\n",
    "    # 计算面积\n",
    "    AOI_area_area = AOI_area.area().divide(ee.Number(1000*1000)).getInfo()\n",
    "    # 缩小\n",
    "    if AOI_area_area < 1:\n",
    "        AOI_area_buffer = AOI_area.buffer(distance=AOI_area_area*-300)\n",
    "    else:\n",
    "        AOI_area_buffer = AOI_area.buffer(distance=-400)\n",
    "\n",
    "    # 扩大包络矩形AOI,保证背景像素占比最大\n",
    "    if AOI_area_area < 1:\n",
    "        AOI_buffer = AOI.buffer(distance=300)\n",
    "    else:\n",
    "        AOI_buffer = AOI.buffer(distance=400)\n",
    "\n",
    "    # 在这个点采用buffer裁剪文件，展示SAR，去除了包含空值的影像\n",
    "    s1_ascending,s1_descending = load_image_collection(AOI_buffer,START_DATE,END_DATE,MIDDLE_DATE,\n",
    "                            dem=DEMNASA,model=models[2],Filter='RefinedLee',FilterSize=30)\n",
    "\n",
    "    # 全包含空值条件下，将图像集合合并为一张图像进行处理\n",
    "    if type(s1_ascending) == ee.imagecollection.ImageCollection:\n",
    "        s1_single_a = s1_ascending.filter(ee.Filter.eq('time_difference',\n",
    "            s1_ascending.aggregate_min('time_difference'))).first().set({'synthesis': 0})\n",
    "    else:\n",
    "        s1_single_a = s1_ascending.set({'synthesis': 1})\n",
    "    if type(s1_descending) == ee.imagecollection.ImageCollection:\n",
    "        s1_single_d = s1_descending.filter(ee.Filter.eq('time_difference',\n",
    "            s1_descending.aggregate_min('time_difference'))).first().set({'synthesis': 0})\n",
    "    else:\n",
    "        s1_single_d = s1_descending.set({'synthesis': 1})\n",
    "\n",
    "    # 加入条件空值，保证在空值情况下图像能够正常相加\n",
    "    condition = s1_single_d.mask().clip(AOI_buffer)\n",
    "    s1_unit_mean = s1_single_a.where(condition, s1_single_a.add(s1_single_d).divide(2)) #转为均值\n",
    "    s1_unit_max = s1_single_a.where(condition, s1_single_a.max(s1_single_d))\n",
    "    # s1_unit_add = s1_single_a.where(condition, s1_single_a.add(s1_single_d))\n",
    "\n",
    "    s1_unit_all = s1_unit_mean.addBands(s1_unit_max)\n",
    "\n",
    "    # 采用S2cloudless生产一张合成的无云图像\n",
    "    s2_sr_median = merge_s2_collection(AOI_buffer,ee.Date('2019-06-01'),ee.Date('2019-09-30'))\n",
    "\n",
    "    for Method in Methods:\n",
    "        if Method == 'SNIC_Kmean':\n",
    "            K = 2\n",
    "        else:\n",
    "            K = 1\n",
    "    for k in range(K):\n",
    "        resultband = resultbands[k]\n",
    "        for Band in Bands:\n",
    "            Map,result=Cluster_math(method=Method,img=s1_unit_all,bands=Band,index=''\n",
    "                    ,visual=False,save=False,region=AOI_buffer)\n",
    "\n",
    "            if AOI_area_buffer.coordinates().getInfo() == []:\n",
    "                FilterBound = AOI_area\n",
    "            else:\n",
    "                FilterBound = AOI_area_buffer\n",
    "\n",
    "            # 分类图转矢量\n",
    "            Union_ex = Reprocess.image2vector(result,\n",
    "                        resultband=resultband,\n",
    "                        GLarea=AOI_area_area,\n",
    "                        FilterBound=FilterBound)\n",
    "            if s1_single_d.get('synthesis').getInfo() == 0:\n",
    "                d_name = s1_single_d.get('system:index').getInfo()\n",
    "                d_date = s1_single_d.date().format('YYYY-MM-dd').getInfo()\n",
    "                d_nodata = s1_single_d.get('numNodata').getInfo()\n",
    "            else:\n",
    "                d_name = 'None'; d_date = 'None' ; d_nodata='None'\n",
    "\n",
    "            if s1_single_a.get('synthesis').getInfo() == 0:\n",
    "                a_name = s1_single_a.get('system:index').getInfo()\n",
    "                a_date = s1_single_a.date().format('YYYY-MM-dd').getInfo()\n",
    "                a_nodata = s1_single_a.get('numNodata').getInfo()\n",
    "            else:\n",
    "                a_name = 'None'; a_date = 'None' ; a_nodata='None'\n",
    "\n",
    "            pd_dict = {'a_name':a_name,'d_name':d_name,\n",
    "                      'a_date':a_date,'d_date':d_date,\n",
    "                      'a_nodata':a_nodata,'d_nodata':d_nodata}\n",
    "\n",
    "            # 导出csv和shp\n",
    "            save_parms.write_pd(Union_ex,i,mode=mode,Method=Method,Band=Band,WithOrigin=resultband,pd_dict=pd_dict,\n",
    "                  Area_real=AOI_area_area,logname=logname,shapname=shpname,calIoU=True)\n",
    "\n",
    "            # 加入升降轨影像名称，加入升降轨影像成像日期，加入升降轨道空值像素个数\n",
    "            if k == 0:\n",
    "                # 导出图像\n",
    "                try:\n",
    "                    Geemap_export(filename=f'{i:04d}'+'_'+str(resultband)+'Ascending_'+a_name+'.tif',collection=False,image=s1_single_a,region=AOI_buffer,scale=10)\n",
    "                    Geemap_export(filename=f'{i:04d}'+'_'+str(resultband)+'Descending_'+d_name+'.tif',collection=False,image=s1_single_d,region=AOI_buffer,scale=10)\n",
    "                    Geemap_export(filename=f'{i:04d}'+'_'+str(resultband)+'s2a_sr_median'+'.tif',collection=False,image=s2_sr_median,region=AOI_buffer,scale=10)\n",
    "                except:\n",
    "                    dir_name = make_dir(f'{i:04d}')\n",
    "                    # 循环输出像素量超标的图像，(裁剪、挨个导出)\n",
    "                    block_list = cut_geometry(AOI_buffer)\n",
    "                    for each in range(len(block_list)):\n",
    "                        Geemap_export(filename=os.path.join(dir_name,f'{i:04d}'+'_'+str(resultband)+'Ascending_'+a_name+'.tif')\n",
    "                                    ,collection=False,image=s1_single_a,region=block_list[each],scale=10)\n",
    "                        Geemap_export(filename=os.path.join(dir_name,f'{i:04d}'+'_'+str(resultband)+'Descending_'+d_name+'.tif')\n",
    "                                    ,collection=False,image=s1_single_d,region=block_list[each],scale=10)\n",
    "                        Geemap_export(filename=os.path.join(dir_name,f'{i:04d}'+'_'+str(resultband)+'s2a_sr_median'+'.tif')\n",
    "                                    ,collection=False,image=s2_sr_median,region=block_list[each],scale=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同的融合方法对应效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.594Z"
    }
   },
   "outputs": [],
   "source": [
    "testCollection = ee.ImageCollection([volumetric_dict['ASCENDING'][2],volumetric_dict['DESCENDING'][2]])\n",
    "\n",
    "testImage_mean = testCollection.mean()\n",
    "testImage_std = testCollection.reduce(ee.Reducer.stdDev())\n",
    "testImage_max = testCollection.max()\n",
    "testImage_min = testCollection.min()\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(AOI, zoom=8)\n",
    "Map.addLayer(volumetric_dict['ASCENDING'][2].select('VV_gamma0flat'),{'min':-18,'max':5},'ASCENDING')\n",
    "Map.addLayer(volumetric_dict['DESCENDING'][2].select('VV_gamma0flat'),{'min':-18,'max':5},'DESCENDING')\n",
    "Map.addLayer(testImage_mean.select('VV_gamma0flat'),{'min':-18,'max':5},'mean')\n",
    "Map.addLayer(testImage_max.select('VV_gamma0flat'),{'min':-18,'max':5},'max')\n",
    "Map.addLayer(testImage_std.select('VV_gamma0flat_stdDev'),{'min':-18,'max':5},'std')\n",
    "Map.addLayer(testImage_min.select('VV_gamma0flat'),{'min':-18,'max':5},'min')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分布情况，并进行归一化与Z-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.627Z"
    }
   },
   "outputs": [],
   "source": [
    "import geemap.chart as chart\n",
    "Bands = [\"VV_gamma0_flatDB\"]\n",
    "ASCENDING_VV_gamma0flat = volumetric_dict['ASCENDING'].select(Bands)\n",
    "DESCENDING_VV_gamma0flat = volumetric_dict['DESCENDING'].select(Bands)\n",
    "\n",
    "# MinMax标准化\n",
    "ASCENDING_Minmax = minmax_norm(ASCENDING_VV_gamma0flat,Bands,scale=10)\n",
    "DESCENDING_Minmax = minmax_norm(DESCENDING_VV_gamma0flat,Bands,scale=10)\n",
    "ASCENDING_MeanStd = meanStd_norm(ASCENDING_VV_gamma0flat,Bands,scale=10)\n",
    "DESCENDING_MeanStd = meanStd_norm(DESCENDING_VV_gamma0flat,Bands,scale=10)\n",
    "\n",
    "Match_Ascending = histogramMatching(ASCENDING_VV_gamma0flat, DESCENDING_VV_gamma0flat,AOI_buffer,Bands,Bands,Histscale=30,maxBuckets=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.647Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"title\": 'Asending Data Distribution',\n",
    "    \"xlabel\": 'Pixel Value (mm)',\n",
    "    \"ylabel\": 'Pixel Count',\n",
    "    \"colors\": ['#1d6b99'],\n",
    "}\n",
    "my_sample = ASCENDING_VV_gamma0flat.sample(AOI_buffer, numPixels=10000,geometries=True)\n",
    "property = 'VV_gamma0flat'\n",
    "chart.feature_histogram(my_sample, property, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.665Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"title\": 'Descending Data Distribution',\n",
    "    \"xlabel\": 'Pixel Value (mm)',\n",
    "    \"ylabel\": 'Pixel Count',\n",
    "    \"colors\": ['#1d6b99'],\n",
    "}\n",
    "my_sample = DESCENDING_VV_gamma0flat.sample(AOI_buffer, numPixels=10000,geometries=True)\n",
    "property = 'VV_gamma0flat'\n",
    "chart.feature_histogram(my_sample, property, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.680Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"title\": 'Ascending MeanStd Data Distribution',\n",
    "    \"xlabel\": 'Pixel Value (mm)',\n",
    "    \"ylabel\": 'Pixel Count',\n",
    "    \"colors\": ['#1d6b99'],\n",
    "}\n",
    "my_sample = ASCENDING_MeanStd.sample(AOI_buffer, numPixels=10000,geometries=True)\n",
    "property = 'VV_gamma0flat'\n",
    "chart.feature_histogram(my_sample, property, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.690Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"title\": 'Descending MeanStd Data Distribution',\n",
    "    \"xlabel\": 'Pixel Value (mm)',\n",
    "    \"ylabel\": 'Pixel Count',\n",
    "    \"colors\": ['#1d6b99'],\n",
    "}\n",
    "my_sample = DESCENDING_MeanStd.sample(AOI_buffer, numPixels=10000,geometries=True)\n",
    "property = 'VV_gamma0_flatDB'\n",
    "chart.feature_histogram(my_sample, property, **options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-02T02:43:36.705Z"
    }
   },
   "outputs": [],
   "source": [
    "# Match_Asc\n",
    "options = {\n",
    "    \"title\": 'Ascending HistMatch Data Distribution',\n",
    "    \"xlabel\": 'Pixel Value (mm)',\n",
    "    \"ylabel\": 'Pixel Count',\n",
    "    \"colors\": ['#1d6b99'],\n",
    "}\n",
    "my_sample = Match_Ascending.sample(AOI_buffer, numPixels=10000,geometries=True)\n",
    "property = 'VV_gamma0_flatDB'\n",
    "chart.feature_histogram(my_sample, property, **options)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
